{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Energy Final Figures\n",
    "*by Fletcher Passow*\n",
    "\n",
    "August 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose and scope\n",
    "\n",
    "This notebook assembles the final figures and summary tables for the Applied Energy paper using results produced by the Kedro pipeline.\n",
    "\n",
    "It:\n",
    "- Loads partitioned results from the Kedro Data Catalog.\n",
    "- Normalizes and groups scenario outputs (sharing, valet, vehicles per fleet, vocation pairs).\n",
    "- Constructs derived metrics (LCOC, utilization, capacity per vehicle).\n",
    "- Builds contrasts against consistent baselines to analyze strategy effects.\n",
    "- Produces publication-ready plots saved to the reporting directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `kedro` environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Kedro IPython extension\n",
    "\n",
    "`%reload_ext kedro.ipython` enables Kedro-specific IPython magics and integrates the project context and Data Catalog into this notebook session. This lets us load datasets via `catalog.load(...)` and reuse project configuration without manual wiring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from matplotlib.ticker import PercentFormatter, FuncFormatter\n",
    "from typing import Tuple\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from e_depot_strategies.pipelines.summarize.nodes import collate_scenario_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SCENARIO_SET = \"quads\"\n",
    "BIG_SCENARIO_SET = \"quads_big\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reporting_groups(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process the partition keys and counterfactuals into grouping columns.\"\"\"\n",
    "    df = df.reset_index()\n",
    "    df[[\"voc_category_i\", \"voc_category_j\"]] = df[\"voc_set\"].str.split(\n",
    "        \"__\", expand=True\n",
    "    )\n",
    "    df[\"task_id\"] = (\n",
    "        df[\"task_id\"].str.extract(r\"(?<=task_)(\\d+)\").astype(int)\n",
    "    )\n",
    "    df[\"veh_scen_id\"] = (\n",
    "        df[\"veh_set\"].str.extract(r\"(?<=veh_scen_)(\\d+)\").astype(int)\n",
    "    )\n",
    "    df[\"Vehicles per Fleet\"] = 5\n",
    "    df.loc[df[\"run_name\"]==BIG_SCENARIO_SET, \"Vehicles per Fleet\"] = 15\n",
    "\n",
    "    # Back to normal flow\n",
    "    df = df.drop(columns=[\"voc_set\", \"scen_id\", \"veh_set\"])\n",
    "    df = df.set_index([\"Vehicles per Fleet\", \"voc_category_i\", \"voc_category_j\", \"valet_set\", \"veh_scen_id\", \"task_id\"])\n",
    "\n",
    "    # Set shared-private dichotomy\n",
    "    df[\"shar_priv\"] = \"shared\"\n",
    "    is_private = df[\"fleet_id\"] != \"shared\"\n",
    "    df.loc[is_private, \"shar_priv\"] = \"private\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def eliminate_infeasible_scenarios(\n",
    "    summs: pd.DataFrame, profs: pd.DataFrame\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Eliminate from summary the scenarios which had infeasible optimizations.\"\"\"\n",
    "    broken_rows = summs.loc[summs[\"problem_status\"] == \"infeasible_or_unbounded\"]\n",
    "    broken_scens = list(broken_rows.index.get_level_values(\"task_id\").unique())\n",
    "    summs = summs.drop(index=broken_scens, level=\"task_id\")\n",
    "    profs = profs.drop(index=broken_scens, level=\"task_id\")\n",
    "    return (summs, profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pairwise_array(ser:pd.Series, levels:Tuple[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"Build a pairwise array using two index levels of a series.\"\"\"\n",
    "    pairs = ser.to_frame()\n",
    "    pairs_opp = pairs.copy()\n",
    "    pairs_opp.index.names = list(reversed(pairs.index.names))\n",
    "    pairs_opp = pairs_opp.swaplevel(levels[0], levels[1])\n",
    "    pairs = pd.concat([pairs, pairs_opp])\n",
    "    pairs = pairs[ser.name]\n",
    "    pairs = pairs.to_frame().reset_index()\n",
    "    pairs = pairs.drop_duplicates([levels[1], ser.name]).set_index(list(levels)).sort_index()\n",
    "    pairs = pairs.unstack(levels[1])\n",
    "    pairs.columns = pairs.columns.droplevel(0)\n",
    "    pairs.sort_index()\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_strategy_labels(valet_col:pd.Series, share_col:pd.Series, sep:str=\", \") -> pd.Series:\n",
    "    inter = valet_col.str.replace(\"_\", \" \").str.title() + sep + share_col.str.title()\n",
    "    inter = pd.Categorical(inter, ordered=True)\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cbar_pct_labels(x, pos) -> str:\n",
    "    \"\"\"Built colorbar percentage labels.\"\"\"\n",
    "    xrep = int(x)\n",
    "    if xrep > 0:\n",
    "        prefix = \"+\"\n",
    "    elif xrep < 0:\n",
    "        prefix = \"-\"\n",
    "    else:\n",
    "        prefix = \"\"\n",
    "    return prefix + str(xrep) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper utilities\n",
    "\n",
    "- `set_reporting_groups`: reshapes partition keys into analysis-friendly indices, sets shared vs private, parses task/vehicle scenario IDs, and standardizes \"Vehicles per Fleet\" (5 or 15).\n",
    "- `eliminate_infeasible_scenarios`: drops scenarios whose optimization failed (infeasible or unbounded).\n",
    "- `build_pairwise_array`: constructs symmetric pivoted matrices for vocation-pair summaries.\n",
    "- `build_strategy_labels`: consistent, compact strategy labels combining valet and sharing settings.\n",
    "- `get_cbar_pct_labels`: human-readable colorbar labels for percent-difference heatmaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "#rc('font',**{'family':'serif','serif':['Helvetica']})\n",
    "default_fig_dims_inches = (6.5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting defaults\n",
    "\n",
    "Figures target paper scale (`sns.set_context('paper')`) with a clean `whitegrid` style and a compact default size. All plots are designed to:\n",
    "- Compare strategies at-a-glance.\n",
    "- Use consistent color palettes and axis formats (percent and currency).\n",
    "- Save reproducibly for downstream manuscript use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_parts = catalog.load(\"depot_profiles_part\")\n",
    "summ_parts = catalog.load(\"depot_summaries_part\")\n",
    "veh_parts = catalog.load(\"selected_vehicle_days_part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_params = catalog.load(\"params:summarize_partitions\")\n",
    "contrast_params = catalog.load(\"params:contrast\")\n",
    "collate_params.update({\"include_partitions\": [SMALL_SCENARIO_SET, BIG_SCENARIO_SET]})\n",
    "contrast_params.update({\"group_cols\": [\"Vehicles per Fleet\", \"voc_category_i\", \"voc_category_j\", \"veh_scen_id\", \"task_id\", \"shar_priv\", \"valet_set\"]})\n",
    "collate_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs_df = collate_scenario_partitions(prof_parts, collate_params)\n",
    "profs_df = set_reporting_groups(profs_df)\n",
    "profs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehs_df = collate_scenario_partitions(veh_parts, collate_params)\n",
    "vehs_df = set_reporting_groups(vehs_df)\n",
    "vehs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summs_df = collate_scenario_partitions(summ_parts, collate_params)\n",
    "summs_df = set_reporting_groups(summs_df)\n",
    "summs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_scens = summs_df.loc[summs_df[\"n_valet_shifts\"].isna(), :]\n",
    "broken_tasks = broken_scens.index.get_level_values(\"task_id\").unique()\n",
    "broken_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and parameters\n",
    "\n",
    "- Datasets loaded: depot profiles (`depot_profiles_part`), depot summaries (`depot_summaries_part`), and selected vehicle-days (`selected_vehicle_days_part`).\n",
    "- Partitions included: `quads` and `quads_big` (see `collate_params`).\n",
    "- Grouping dimensions for contrasts: `Vehicles per Fleet`, `voc_category_i/j`, `veh_scen_id`, `task_id`, `shar_priv`, and `valet_set`.\n",
    "- We identify tasks with missing valet outputs (e.g., `n_valet_shifts`) for awareness; these can be excluded to avoid bias in contrast calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore valet presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valets_df = summs_df.loc[:, [\"valets_per_shift\"]]\n",
    "valets_df[\"clean\"] = valets_df[\"valets_per_shift\"].str.replace(\"[\", \"\")\n",
    "valets_df[\"clean\"] = valets_df[\"clean\"].str.replace(\"]\", \"\")\n",
    "valets_df[\"clean\"] = valets_df[\"clean\"].str.replace(\" \", \"\")\n",
    "valets_df[\"list\"] = valets_df[\"clean\"].str.split(\".\")\n",
    "for i in range(3):\n",
    "    valets_df[f\"valets_shift_{i}\"] = valets_df[\"list\"].transform(lambda s: float(s[i]))\n",
    "valets_df = valets_df.drop(columns=[\"valets_per_shift\", \"clean\", \"list\"])\n",
    "valets_df = valets_df.query(\"valet_set =='with_valet'\")\n",
    "valets_df.sum(axis=0) / valets_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valet presence sanity check\n",
    "\n",
    "We parse and summarize `valets_per_shift` to confirm valet staffing is present and consistent in `with_valet` runs. This helps explain capacity and cost shifts where valet availability is a driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_cols = list(filter(lambda x: re.compile(r\"^cost_\").match(x), summs_df.columns))\n",
    "summs_df[\"total_cost_dollars\"] = summs_df[cost_cols].sum(axis=1)\n",
    "\n",
    "precursor = summs_df.groupby(contrast_params[\"group_cols\"]).agg(\"sum\")\n",
    "precursor = precursor.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Calculate derived measurements\n",
    "precursor[\"potential_energy_kwh\"] = precursor[\"depot_capacity_kw\"] * 24\n",
    "precursor[\"utilization\"] = (\n",
    "    precursor[\"energy_delivered_kwh\"] / precursor[\"potential_energy_kwh\"]\n",
    ")\n",
    "precursor[\"cost_dollars_per_kwh\"] = (\n",
    "    precursor[\"total_cost_dollars\"] / precursor[\"energy_delivered_kwh\"]\n",
    ")\n",
    "precursor[\"capacity_kw_per_veh\"] = precursor[\"depot_capacity_kw\"] / precursor[\"n_vehicles\"]\n",
    "precursor[\"cost_upfront_per_kwh\"] = precursor[\"cost_plugs_dollars\"] / precursor[\"energy_delivered_kwh\"]\n",
    "precursor[\"cost_continue_per_kwh\"] = precursor[\"cost_dollars_per_kwh\"] - precursor[\"cost_upfront_per_kwh\"]\n",
    "\n",
    "precursor = precursor.droplevel(\"task_id\", \"index\")\n",
    "precursor = precursor.sort_index()\n",
    "precursor = precursor.melt(ignore_index=False)\n",
    "precursor = precursor.set_index(\"variable\", append=True)\n",
    "precursor = precursor.unstack([\"Vehicles per Fleet\", \"shar_priv\", \"valet_set\"])\n",
    "precursor = precursor.droplevel(0, \"columns\")\n",
    "\n",
    "idx_df = precursor.columns.to_frame()\n",
    "idx_df[\"val_type\"] = \"orig\"\n",
    "idx_df = idx_df[[\"val_type\", \"Vehicles per Fleet\", \"shar_priv\", \"valet_set\"]]\n",
    "precursor.columns = pd.MultiIndex.from_frame(idx_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived metrics and contrast setup\n",
    "\n",
    "We compute:\n",
    "- `potential_energy_kwh = depot_capacity_kw × 24`,\n",
    "- `utilization = energy_delivered_kwh / potential_energy_kwh`,\n",
    "- `cost_dollars_per_kwh = total_cost_dollars / energy_delivered_kwh`,\n",
    "- `capacity_kw_per_veh = depot_capacity_kw / n_vehicles`,\n",
    "- Split levelized cost into `cost_upfront_per_kwh` (plugs) and `cost_continue_per_kwh` (energy + demand + valet).\n",
    "\n",
    "We then reindex values so each metric can be contrasted relative to baselines later (e.g., Private, No Valet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt tabular summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the main table using \"Private, No Valet\" as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = deepcopy(precursor)\n",
    "for val_type, n_vehs, share, valet in contrast.columns:\n",
    "    contrast[(\"diff\", n_vehs, share, valet)] = contrast[(\"orig\", n_vehs, share, valet)] - contrast[(\"orig\", n_vehs, \"private\", \"no_valet\")]\n",
    "    contrast[(\"pct_diff\", n_vehs, share, valet)] = contrast[(\"diff\", n_vehs, share, valet)] / contrast[(\"orig\", n_vehs, \"private\", \"no_valet\")] * 100\n",
    "    contrast.loc[contrast[(\"diff\", n_vehs, share, valet)] == 0, (\"pct_diff\", n_vehs, share, valet)] = 0\n",
    "\n",
    "contrast = contrast.unstack(\"variable\")\n",
    "contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"cost_dollars_per_kwh\", \"capacity_kw_per_veh\", \"cost_upfront_per_kwh\", \"cost_continue_per_kwh\"]\n",
    "tab_df = contrast.loc[:, (\"pct_diff\", slice(None), slice(None), slice(None), keep_cols)]\n",
    "tab_df = tab_df.droplevel([0], \"columns\")\n",
    "\n",
    "util_df = contrast.loc[:, (\"diff\", slice(None), slice(None), slice(None), \"utilization\")]\n",
    "util_df = util_df.droplevel([0], \"columns\")\n",
    "tab_df = tab_df.merge(util_df, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "tab_df = tab_df.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\", \"variable\"])\n",
    "tab_df.name = \"value\"\n",
    "tab_df = tab_df.reset_index()\n",
    "tab_df = tab_df.groupby([\"variable\", \"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])[\"value\"].describe(percentiles=[0.05, 0.5, 0.95])\n",
    "tab_df = tab_df.loc[:, [\"50%\", \"5%\", \"95%\"]].round(1).astype(str)\n",
    "tab_df[\"cell_text\"] = tab_df[\"50%\"] + \"[\" + tab_df[\"5%\"] + \",\" + tab_df[\"95%\"]+ \"]\"\n",
    "tab_df[\"cell_text\"].unstack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: changes vs Private, No Valet\n",
    "\n",
    "For each metric, we show percent change relative to the `Private, No Valet` baseline by vocation-pair and vehicle scenario, then report the distribution:\n",
    "- Median with 5th and 95th percentiles as `[p5, p95]`.\n",
    "- Metrics: LCOC (`$/kWh`), capacity per vehicle (`kW/veh`), upfront vs continuing cost split, and the absolute difference in utilization.\n",
    "\n",
    "Interpretation: Negative values indicate savings (lower cost or capacity) relative to the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build another table, this time using \"Shared, No Valet\" as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_shared = deepcopy(precursor)\n",
    "for val_type, n_vehs, share, valet in from_shared.columns:\n",
    "    from_shared[(\"diff\", n_vehs, share, valet)] = from_shared[(\"orig\", n_vehs, share, valet)] - from_shared[(\"orig\", n_vehs, \"shared\", \"no_valet\")]\n",
    "    from_shared[(\"pct_diff\", n_vehs, share, valet)] = from_shared[(\"diff\", n_vehs, share, valet)] / from_shared[(\"orig\", n_vehs, \"shared\", \"no_valet\")] * 100\n",
    "    from_shared.loc[from_shared[(\"diff\", n_vehs, share, valet)] == 0, (\"pct_diff\", n_vehs, share, valet)] = 0\n",
    "\n",
    "from_shared = from_shared.unstack(\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"cost_dollars_per_kwh\", \"capacity_kw_per_veh\", \"cost_upfront_per_kwh\", \"cost_continue_per_kwh\"]\n",
    "tab_df = from_shared.loc[:, (\"pct_diff\", slice(None), slice(None), slice(None), keep_cols)]\n",
    "tab_df = tab_df.droplevel([0], \"columns\")\n",
    "\n",
    "util_df = from_shared.loc[:, (\"diff\", slice(None), slice(None), slice(None), \"utilization\")]\n",
    "util_df = util_df.droplevel([0], \"columns\")\n",
    "tab_df = tab_df.merge(util_df, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "tab_df = tab_df.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\", \"variable\"])\n",
    "tab_df.name = \"value\"\n",
    "tab_df = tab_df.reset_index()\n",
    "tab_df = tab_df.groupby([\"variable\", \"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])[\"value\"].describe(percentiles=[0.05, 0.5, 0.95])\n",
    "tab_df = tab_df.loc[:, [\"50%\", \"5%\", \"95%\"]].round(1).astype(str)\n",
    "tab_df[\"cell_text\"] = tab_df[\"50%\"] + \"[\" + tab_df[\"5%\"] + \",\" + tab_df[\"95%\"]+ \"]\"\n",
    "tab_df[\"cell_text\"].unstack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: changes vs Shared, No Valet\n",
    "\n",
    "We repeat the summary using `Shared, No Valet` as the baseline to isolate the effect of valet staffing within shared depots, separating sharing benefits from valet-specific effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt graphical description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_voc = contrast.index.get_level_values(\"voc_category_i\").to_series().values == contrast.index.get_level_values(\"voc_category_j\").to_series().values\n",
    "col_name = [\"capacity_kw_per_veh\", \"cost_dollars_per_kwh\"]\n",
    "same_voc = contrast.loc[same_voc, (\"pct_diff\", slice(None), \"shared\", \"no_valet\", col_name)]\n",
    "same_voc.describe(percentiles=[0.05, 0.5, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [\"capacity_kw_per_veh\", \"cost_dollars_per_kwh\"]\n",
    "plot_df = contrast.loc[:, (\"pct_diff\", slice(None), slice(None), slice(None), col_name)]\n",
    "#plug_loss_df = contrast.loc[:, (\"diff\", slice(None), slice(None), slice(None), [\"n_plugs_high\", \"n_plugs_med\"])]\n",
    "#plot_df = pd.concat([plot_df, plug_loss_df], axis=1)\n",
    "plot_df = plot_df.droplevel([0], \"columns\")\n",
    "plot_df = plot_df.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"]).reset_index()\n",
    "plot_df[\"savings_dollars_per_kwh\"] = -plot_df[\"cost_dollars_per_kwh\"]\n",
    "plot_df[\"reduction_kw_per_veh\"] = -plot_df[\"capacity_kw_per_veh\"]\n",
    "#plot_df[\"Dropped Higher-Power Charger\"] = np.logical_or(plot_df[\"n_plugs_high\"] < 0, plot_df[\"n_plugs_med\"] < 0)\n",
    "sing_voc_col = \"Sharing fleets have\\nsame vocation\"\n",
    "plot_df[sing_voc_col] = (plot_df[\"voc_category_i\"] == plot_df[\"voc_category_j\"]) & (plot_df[\"shar_priv\"] == \"shared\")\n",
    "plot_df[sing_voc_col] = pd.Categorical(plot_df[sing_voc_col], categories=[True, False], ordered=True) # \"Fake 1\", \"Fake 2\"\n",
    "plot_df[\"Strategy\"] = build_strategy_labels(plot_df[\"valet_set\"], plot_df[\"shar_priv\"])\n",
    "plot_df = plot_df.sort_values(sing_voc_col)\n",
    "\n",
    "# plt.figure(figsize=default_fig_dims_inches)\n",
    "markers = {\n",
    "    True: MarkerStyle('>'),\n",
    "    False: MarkerStyle('o'),\n",
    "    \"Fake 1\": MarkerStyle('<'),\n",
    "    \"Fake 2\": MarkerStyle('.'),\n",
    "}\n",
    "g = sns.relplot(\n",
    "    data=plot_df,\n",
    "    x=\"reduction_kw_per_veh\",\n",
    "    y=\"cost_dollars_per_kwh\",\n",
    "    hue=\"Strategy\",\n",
    "    style=sing_voc_col,\n",
    "    col=\"Vehicles per Fleet\",\n",
    "    kind=\"scatter\",\n",
    "    markers=markers,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.25,\n",
    "    alpha=0.7,\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(xmax=100, decimals=0))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(xmax=100, decimals=0))\n",
    "    ax.set_xlabel(\"Reduction in Installed Capacity [kW/veh]\")\n",
    "    ax.set_ylabel(\"Change in Levelized Cost [$/kWh]\")\n",
    "    ax.hlines(y=0, xmin=ax.get_xlim()[0], xmax=ax.get_xlim()[1], linestyles=\"dashed\", colors=\"gray\")\n",
    "    ax.vlines(x=0, ymin=ax.get_ylim()[0], ymax=ax.get_ylim()[1], linestyles=\"dashed\", colors=\"gray\")\n",
    "#sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.7, 0.9), ncols=1) #bbox_to_anchor=(0.4, 0), ncols=2)\n",
    "\n",
    "catalog.save(\"cost_reduce_vs_capacity_savings\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Capacity reduction vs LCOC change\n",
    "\n",
    "- X-axis: percent reduction in installed capacity per vehicle (to the right is better).\n",
    "- Y-axis: percent change in levelized cost per kWh (down is better).\n",
    "- Markers indicate whether fleets in a pair share the same vocation; colors denote strategy.\n",
    "\n",
    "Quadrants make trade-offs explicit: bottom-right means both lower cost and lower capacity installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_cols = [\"n_plugs_low\", \"n_plugs_med\", \"n_plugs_high\"]\n",
    "plugs = contrast.loc[:, (\"orig\", slice(None), slice(None), slice(None), plug_cols)]\n",
    "plugs = plugs.droplevel([0], \"columns\")\n",
    "plugs = plugs.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])\n",
    "plugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_plugs = plugs.groupby([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"]).mean()\n",
    "#mean_plugs = mean_plugs.div(mean_plugs.sum(axis=1), axis=0)\n",
    "mean_plugs = mean_plugs.melt(ignore_index=False, var_name=\"Plug Power Level\", value_name=\"plug_share\")\n",
    "mean_plugs[\"Plug Power Level\"] = mean_plugs[\"Plug Power Level\"].str.extract(r\"(?<=n_plugs_)(.+)\")\n",
    "mean_plugs[\"Plug Power Level\"] = mean_plugs[\"Plug Power Level\"].str.capitalize()\n",
    "mean_plugs[\"Plug Power Level\"] = pd.Categorical(mean_plugs[\"Plug Power Level\"], categories=[\"Low\", \"Med\", \"High\"], ordered=True)\n",
    "mean_plugs = mean_plugs.reset_index()\n",
    "mean_plugs[\"Strategy\"] = build_strategy_labels(mean_plugs[\"valet_set\"], mean_plugs[\"shar_priv\"], sep=\",\\n\")\n",
    "mean_plugs = mean_plugs.sort_values([\"Vehicles per Fleet\", \"Strategy\", \"Plug Power Level\"], ascending=True)\n",
    "mean_plugs[\"plug_cum\"] = mean_plugs.groupby([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])[\"plug_share\"].cumsum()\n",
    "mean_plugs[\"Plug Power Level\"] = mean_plugs[\"Plug Power Level\"].cat.reorder_categories(new_categories=list(reversed(mean_plugs[\"Plug Power Level\"].cat.categories)), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_plugs.loc[mean_plugs[\"valet_set\"] == \"no_valet\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=default_fig_dims_inches)\n",
    "g = sns.catplot(\n",
    "    data=mean_plugs.iloc[::-1],\n",
    "    x=\"Strategy\",\n",
    "    y=\"plug_cum\",\n",
    "    hue=\"Plug Power Level\",\n",
    "    dodge=False,\n",
    "    palette=\"YlOrBr_r\",\n",
    "    kind=\"bar\",\n",
    "    col=\"Vehicles per Fleet\",\n",
    "    #row=\"Has High Plugs\",\n",
    "    margin_titles=True,\n",
    ")\n",
    "for i, ax in enumerate(g.axes.flat):\n",
    "    ax.set_ylabel(\"Mean Number of Plugs per Depot\")\n",
    "    ax.tick_params(axis='x', labelrotation=45)\n",
    "    # ax.text(0.02, 1.05, f'({chr(97 + i)})', transform=ax.transAxes,\n",
    "    #     fontsize=16, fontweight=\"bold\", ha='left', va='top')\n",
    "sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.44, -0.05), ncols=3)\n",
    "\n",
    "catalog.save(\"plug_contribs\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Plug mix by strategy\n",
    "\n",
    "Stacked bars show the mean number of plugs per depot by power level (Low/Med/High), comparing strategies and fleet sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_cols = [\"cost_demand_dollars\", \"cost_energy_dollars\", \"cost_plugs_dollars\", \"cost_valet_dollars\", \"energy_delivered_kwh\"]\n",
    "costs = contrast.loc[:, (\"orig\", slice(None), slice(None), slice(None), cost_cols)]\n",
    "costs = costs.droplevel([0], \"columns\")\n",
    "costs = costs.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])\n",
    "abs_cols = list(costs.columns)\n",
    "for col in abs_cols:\n",
    "    costs[f\"{col}_per_kwh\"] = costs[col] / costs[\"energy_delivered_kwh\"]\n",
    "costs = costs.drop(abs_cols + [\"energy_delivered_kwh_per_kwh\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_costs = costs.groupby([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"]).mean()\n",
    "#mean_costs = mean_costs.div(mean_costs.sum(axis=1), axis=0)\n",
    "mean_costs = mean_costs.melt(ignore_index=False, var_name=\"Cost Type\", value_name=\"cost_share\")\n",
    "mean_costs[\"Cost Type\"] = mean_costs[\"Cost Type\"].str.extract(r\"(?<=cost_)(.+)(?=_dollars_per_kwh)\")\n",
    "mean_costs[\"Cost Type\"] = mean_costs[\"Cost Type\"].str.capitalize()\n",
    "mean_costs[\"Cost Type\"] = pd.Categorical(mean_costs[\"Cost Type\"], categories=[\"Energy\", \"Demand\", \"Plugs\", \"Valet\"], ordered=True)\n",
    "mean_costs = mean_costs.reset_index()\n",
    "mean_costs[\"Strategy\"] = build_strategy_labels(mean_costs[\"valet_set\"], mean_costs[\"shar_priv\"], sep=\",\\n\")\n",
    "mean_costs = mean_costs.sort_values([\"Vehicles per Fleet\", \"Strategy\", \"Cost Type\"], ascending=True)\n",
    "mean_costs[\"cost_cum\"] = mean_costs.groupby([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])[\"cost_share\"].cumsum()\n",
    "mean_costs[\"Cost Type\"] = mean_costs[\"Cost Type\"].cat.reorder_categories(new_categories=list(reversed(mean_costs[\"Cost Type\"].cat.categories)), ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=default_fig_dims_inches)\n",
    "g = sns.catplot(\n",
    "    data=mean_costs.iloc[::-1],\n",
    "    x=\"Strategy\",\n",
    "    y=\"cost_cum\",\n",
    "    hue=\"Cost Type\",\n",
    "    dodge=False,\n",
    "    palette=\"husl\",\n",
    "    kind=\"bar\",\n",
    "    col=\"Vehicles per Fleet\",\n",
    ")\n",
    "# ref_df = mean_costs.set_index([\"valet_set\", \"shar_priv\", \"Cost Type\"])\n",
    "# ref_val = ref_df.loc[(\"no_valet\", \"private\", \"Plugs\"), \"cost_cum\"]\n",
    "\n",
    "def add_hline(data: pd.DataFrame, color=None):\n",
    "    ref_df = data.set_index([\"valet_set\", \"shar_priv\", \"Cost Type\"])\n",
    "    ref_val = ref_df.loc[(\"no_valet\", \"private\", \"Plugs\"), \"cost_cum\"]\n",
    "    ax = plt.gca()\n",
    "    ax.hlines(y=ref_val, xmin=ax.get_xlim()[0], xmax=ax.get_xlim()[1], linestyles=\"--\", colors=\"gray\")\n",
    "\n",
    "g.map_dataframe(add_hline)\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_ylabel(\"Cost Contribution [$/kWh]\")\n",
    "    ax.tick_params(axis='x', labelrotation=45)\n",
    "    ax.yaxis.set_major_formatter('${x:1.2f}')\n",
    "sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.44, -0.05), ncols=4)\n",
    "\n",
    "catalog.save(\"cost_contribs\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Cost contributions to LCOC\n",
    "\n",
    "Bars stack per-kWh contributions from Energy, Demand, Plugs (upfront), and Valet. The dashed line references the `Plugs` contribution in the `Private, No Valet` baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util = contrast.loc[:, (\"orig\", slice(None), slice(None), slice(None), \"utilization\")]\n",
    "util = util.droplevel([0], \"columns\")\n",
    "util = util.stack([\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"])\n",
    "util = util.reset_index()\n",
    "util[\"Strategy\"] = build_strategy_labels(util[\"valet_set\"], util[\"shar_priv\"])\n",
    "\n",
    "plt.figure(figsize=default_fig_dims_inches)\n",
    "g = sns.displot(\n",
    "    data=util,\n",
    "    x=\"utilization\",\n",
    "    hue=\"Strategy\",\n",
    "    kind=\"ecdf\",\n",
    "    col=\"Vehicles per Fleet\",\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(xmax=1))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(xmax=1))\n",
    "    ax.set_xlabel(\"Charger Utilization\")\n",
    "    ax.set_ylabel(\"Proportion of Scenarios\")\n",
    "sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.44, 0), ncols=2)\n",
    "\n",
    "catalog.save(\"utilization_dists\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Charger utilization distributions\n",
    "\n",
    "The ECDF shows the distribution of average utilization across scenarios for each strategy and fleet size.\n",
    "\n",
    "Interpretation: Curves further right indicate generally higher utilization (i.e., more of the capacity is used over time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore how vocation pairs influence results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_heat_array(data: pd.DataFrame, color=None, sum_col: str = None, **kwargs) -> Axes:\n",
    "    voc_cols = (\"voc_category_i\", \"voc_category_j\")\n",
    "    heat = data.groupby(list(voc_cols))[sum_col].agg([\"mean\", \"std\"])\n",
    "    heat = heat.reset_index()\n",
    "    heat[list(voc_cols)] = heat[list(voc_cols)].transform(lambda x: x.str.replace(\"_\", \" \").str.title())\n",
    "    heat = heat.set_index(list(voc_cols))\n",
    "    heat[\"mean_annot\"] = heat[\"mean\"].round(1).astype(str)\n",
    "    mean_pairs = build_pairwise_array(heat[\"mean\"], voc_cols)\n",
    "    ax = sns.heatmap(\n",
    "        mean_pairs,\n",
    "        # annot=mean_pairs,\n",
    "        **kwargs,\n",
    "    ) \n",
    "    ax.grid(visible=False)\n",
    "    ax.set_xlabel(\"Potential Partner Vocation\")\n",
    "    ax.set_ylabel(\"Your Vocation\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, investigate how vocation pairs influence LCOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridder = contrast.loc[:, (\"pct_diff\", slice(None), slice(None), slice(None), \"cost_dollars_per_kwh\")]\n",
    "gridder = gridder.droplevel([0], \"columns\")\n",
    "inter_cols = [\"Vehicles per Fleet\", \"valet_set\", \"shar_priv\"]\n",
    "gridder = gridder.stack(inter_cols).reset_index(inter_cols, drop=False)\n",
    "gridder[\"Strategy\"] = build_strategy_labels(gridder[\"valet_set\"], gridder[\"shar_priv\"])\n",
    "gridder = gridder.loc[gridder[\"shar_priv\"]==\"shared\", :]\n",
    "gridder[\"Strategy\"] = gridder[\"Strategy\"].cat.remove_unused_categories()\n",
    "gridder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a common color map and normalization\n",
    "map_vals = gridder['cost_dollars_per_kwh']\n",
    "vmin, vmax = map_vals.min(), map_vals.max()\n",
    "cmap = sns.color_palette(\"light:b_r\", as_cmap=True)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "# Create a colorbar with a single scalar mappable\n",
    "fig = plt.figure()\n",
    "cbar = fig.colorbar(mappable=sm, ax=plt.gca(), orientation='vertical', format=FuncFormatter(get_cbar_pct_labels), label=\"Avg. Pct. Change in Cost [$/kWh]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=gridder, col=\"Strategy\", row=\"Vehicles per Fleet\", margin_titles=True)\n",
    "g.map_dataframe(\n",
    "    build_heat_array,\n",
    "    sum_col=\"cost_dollars_per_kwh\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    cmap=cmap,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    ")\n",
    "g.set_titles(col_template=\"Strategy =\\n{col_name}\", row_template=\"Vehicles per\\nFleet = {row_name}\")\n",
    "g.set_axis_labels(x_var=\"Potential Partner\\nVocation\", y_var=\"Your Vocation\")\n",
    "#g.tick_params(axis=\"x\", rotation=45)\n",
    "#g.figure.set_size_inches(w=12, h=8)\n",
    "catalog.save(\"sharing_cost_by_pair\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: LCOC impact by vocation pair\n",
    "\n",
    "Each cell shows the average percent change in `$/kWh` for sharing strategies, grouped by your vocation (rows) and partner vocation (columns).\n",
    "\n",
    "Interpretation: Cooler colors (negative) indicate cost savings from pairing; patterns reveal complementary duty profiles across vocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=melted_comp,\n",
    "    x=\"effective_size\",\n",
    "    y=\"capacity_kw_per_veh\",\n",
    "    hue=\"Vocation\",\n",
    "    kind=\"line\",\n",
    "    estimator=\"mean\",\n",
    "    errorbar=None,\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(xmax=100, decimals=0))\n",
    "    ax.set_ylabel(\"Reduction in Installed Capacity [kW/veh]\")\n",
    "    ax.set_xlabel(\"Fleet Size [vehs]\")\n",
    "    ax.set_ylim(bottom=0, top=ax.get_ylim()[1])\n",
    "    #ax.set_xlim(left=0, right=ax.get_xlim()[1])\n",
    "\n",
    "#sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.4, 0), ncols=2)\n",
    "\n",
    "catalog.save(\"capacity_savings_by_fleet_size\", g.figure)\n",
    "g.figure\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective fleet size comparison (same-vocation pairs)\n",
    "\n",
    "We compare capacity reductions for private vs shared (with valet) scenarios by an \"effective size\" (5/10/15/30 vehicles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot load-duration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = profs_df.reset_index()\n",
    "grp_cols = [\"Vehicles per Fleet\", \"voc_category_i\", \"voc_category_j\", \"valet_set\", \"shar_priv\", \"veh_scen_id\"]\n",
    "\n",
    "depot_power_ser = power.groupby(grp_cols + [\"time\"], observed=True)[\"avg_power_kw\"].sum()\n",
    "plot_df = depot_power_ser.reset_index()\n",
    "plot_df = plot_df.sort_values(grp_cols + [\"avg_power_kw\"], ascending=False)\n",
    "\n",
    "def norm(x: pd.Series) -> pd.Series:\n",
    "    return np.arange(1, x.count() + 1) / (x.count() + 1) * 100\n",
    "\n",
    "plot_df[\"util_rate_pct\"] = plot_df.groupby(grp_cols, observed=True)[\"avg_power_kw\"].transform(norm)\n",
    "plot_df = plot_df.reset_index(drop=True)\n",
    "plot_df = plot_df.sort_values(grp_cols)\n",
    "plot_df[\"Strategy\"] = build_strategy_labels(plot_df[\"valet_set\"], plot_df[\"shar_priv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    plot_df,\n",
    "    x=\"util_rate_pct\",\n",
    "    y=\"avg_power_kw\",\n",
    "    hue=\"Strategy\",\n",
    "    col=\"Vehicles per Fleet\",\n",
    "    kind=\"line\",\n",
    "    errorbar=\"ci\",\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel(\"Capacity Utilization Rate\")\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(xmax=100))\n",
    "    ax.set_ylabel(\"Power [kW]\")\n",
    "sns.move_legend(g, loc=\"upper center\", bbox_to_anchor=(0.44, 0), ncols=2)\n",
    "\n",
    "catalog.save(\"load_duration_by_strategy\", g.figure)\n",
    "g.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Load-duration curves by strategy\n",
    "\n",
    "We aggregate depot power over time and convert to a load-duration curve (power vs percentile of time)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-depot-strategies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
